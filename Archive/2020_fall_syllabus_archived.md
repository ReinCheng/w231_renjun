# Behind the Data: Humans and Values | Fall 2020

**Instructors:**  
* Morgan Ames, [morganya@berkeley.edu](mailto:morganya@berkeley.edu)
* Jared Maslin, [jfmyq9@berkeley.edu](mailto:jfmyq9@berkeley.edu)

* Deirdre Mulligan, [dkm@ischool.berkeley.edu](mailto:dkm@ischool.berkeley.edu)

**TA:** Anna Jacobson, [annacjacobson@berkeley.edu](mailto:annacjacobson@berkeley.edu)

**Synchronous Section Times:** 
* Section W-231-1, Monday 4:00-5:30 PT 
* Section W-231-2, Wednesday 4:00-5:30 PT

**Office Hours** are the hour before synch sessions, or by appointment, in Zoom.

## Course Description:
This course provides an introduction to the legal, policy, and ethical implications of data. The course will examine how these issues arise throughout the full life cycle of data science from collection, to storage, processing, analysis and use including, privacy, surveillance, security, classification, discrimination, decisional autonomy, and duties to warn or act. Case studies will be used to explore these issues across various domains such as criminal justice, national security, health, marketing, politics, education, automotive, employment, athletics, and development. Attention will be paid to legal and policy constraints and considerations that attach to specific domains as well as particular data-types, collection methods, and institutions. Technical, legal, and market approaches to mitigating and managing discrete and compound sets of concerns will be introduced, and the strengths and benefits of competing and complementary approaches will be explored. **Prerequisites:** Students must complete MIDS courses 201 and 203 before enrolling in this course.

## Links to Course Pages: 
1. Course Github: https://github.com/UC-Berkeley-I-School/w231
2. Course Blog: https://blogs.ischool.berkeley.edu/w231/
3. Course Slack Channel: #w231-announce
4. Course Signup sheets:
   * Introductory Survey: https://goo.gl/forms/Yht3jSSFUxXT8hKq2
   * Public Advocacy Blog Assignment Sign-Ups: https://goo.gl/6uZY62
   * Final Project Presentation Sign-Ups: https://goo.gl/krXaCd
   * Anonymous Course Feedback: https://forms.gle/yxEHyfshm8FGLgqz8

## Course Evaluation:
* Participation (25%)
  * Synchronous session discussion (15%). Attend and actively participate in every synchronous session.
  * Asynchronous participation (10%). This class relies on readings and asynch content. Both are
necessary for the synch session, and are important for the course. Complete both before the synch
session each week (note that watching is tracked automatically in ISVC). 
On Slack I will also post *reading response questions* some weeks. Please write a 2-3
paragraph brainstorm response to the questions and send them to me via Slack by noon the Monday
before our synch session (copy/pasting into Slack preferred, PDF attachment acceptable). We will
not be individually grading these but they will in aggregate contribute to your asynch participation
(and will also help prepare you for our synch discussions each week).
* [Assignments](Assignments) (40%):
  * Descriptions are in the Assignments folder in the class git repository, and linked from here. All assignments are due 11:59pm Pacific Time (PT) on the date noted, in ISVC unless otherwise indicated in the assignment description. Please convert docx and pptx files to pdf.
  * [Application of Belmont Principles](Assignments/1_Application_of_Belmont_Principles.md) (8%)
  * [Privacy Policy Assignment](Assignments/2_Privacy_Policy_Assignment.md) (8%)
  * [Peer Feedback Assignment](Assignments/3_Peer_Feedback_Assignment.md) (8%)
  * [Group Legal/Ethical Analysis](Assignments/4_Group_Legal_Ethical_Analysis.md) (8%)
  * [Public Advocacy Blog Post](Assignments/0_Public_Advocacy_Blog_Post.md) (8%)
* [Final Project](Assignments/5_Final_Project_Overview.md) (35%): 5% outline, 30% final write-up

**Assignment Late Policy:** If you cannot make a deadline, contact us as soon as you can to make a plan for an alternate due date. We offer five floating late days penalty-free, but beyond those five days late assignments may be docked up to 5 points per day late. 

**Writing Practices:** This course is focused on not only teaching you about the human values and ethical implications of data science, but to communicate effectively about what you've learned. As such, the assignments (as well as the course discussions) are focused on giving you lots of practice clearly stating your position and backing it up using course materials and other evidence. Throughout, please strive to:
* Clearly and accurately reference the argument/arguments of the readings you are drawing on, using your own words and without merely quoting.
* Take a position on this argument, but do so in a way that uses sound logic or credible evidence to support your position. You should avoid referencing personal experiences as 'proof' - stick to what is stated in the readings or other evidence-based sources.

The purpose of writing is to engage with and think about the course materials and to practice communicating clearly and persuasively. Writing about a topic is a great way to think deeply about it. In particular, the reading responses provide an opportunity to work on thinking _critically_ about technology and information systems, the role they play, and influence they have in society. _What does it mean to think critically?_ This does not mean simply to be negative, to harbor dystopian views about technology, or to be a pessimist, or a luddite, or a crank. It does mean being skeptical. It means considering the evidence presented and its strengths and weaknesses. It means examining the arguments being made and their logic. It means being willing to examine your own assumptions, biases, and blindspots and potentially to change your mind in the face of strong evidence.

**Citation Practices:** When writing analytically you will often draw upon the ideas and arguments of others to develop your own analysis. It’s important to distinguish your own ideas from the ideas of others. A mistake some students make is to assume that there is one correct or optimal answer to an essay question and that the sequence of words for a correct answer cannot be “owned” by anyone. To the contrary, writing in your own words is part of thoroughly absorbing ideas and transforming them into your tools of analysis. On ethical grounds proper citation practices mean giving credit to those who’ve come up with the ideas and arguments you are borrowing from.

Avoiding inadvertent plagiarism starts with good note-taking practices. Make sure to keep notes on sources. When you write down (or copy and paste) something word-for-word from a reading into your own note-taking files, put it in double quotes (“”) and note the source and page number. This will make for easier work later on when you draw from your notes while writing up your assignments.

Citing involves two components:
1. **In-text citations** – where you indicate the source of an idea or quote in the body of your essay. In-text citations should look like this: (Author year). An in-text citation is placed at the end of the sentence. Here’s an example: _Women's uses of the telephone in the early 20th century went against the intentions of designers (Fischer 1992)._ For multiple citations, separate with semicolons, and where there are two authors, list both authors’ last names. For three or more authors, list the first author’s last name and follow with ‘et al.’ Here are examples: (Ames 2019; Oreglia and Geiger 2009; Srinivasan et al. 2000). Be very sure to put word-for-word references to texts in double quotes (“”) and include an in-text citation with page number in the form of (AUTHOR year: pg#), e.g. (Ames 2019: 54). Please note that extensive paraphrasing where you change a few words in a sentence or paragraph from a published source but leave it essentially the same is plagiarism and not acceptable. Furthermore, wholesale borrowing of the larger structure, argument, and evidence of a published piece is also plagiarism.
1. **A list of references** – at the end of your document, where you list the full details for any source that you’ve used.mA reference to each cited text should be placed in the references section at the end of your written piece. The references should include the names of all authors, the title of the cited piece, year of publication, volume and issue numbers (for periodicals), page numbers (for periodicals and book chapters in edited books), publisher name and city (for books). APA or MLA format are widespread standards that you can easily find online. See the library source page on this: http://www.lib.berkeley.edu/instruct/guides/citations.html. If you are citing online resources, here are some guidelines on how to do so: http://www.lib.berkeley.edu/MRC/mla.html#online. If there are pieces of information that are missing (for example, a clear author), you should at the very least have the title of the page, the url, and the date when you visited it.

**A Note on Plagiarism:** Some cases of plagiarism stem from a poor understanding of how and when to cite sources. We will clarify expectations and best practices up front at the beginning of the semester. In addition, we expect all students to abide by the Berkeley Student Code of Conduct (see http://students.berkeley.edu/uga/conduct.pdf). Cases of plagiarism will not be tolerated. The consequences include failing the assignment, a referral to the Center for Student Conduct and Community Standards, possibly a failed grade in the course, and even expulsion from the program. 

Plagiarism includes copying material from a book or article (word-for-word or paraphrased) without citing the source as well as extensively summarizing the written work of someone else without clarifying that the ideas and analysis are not your own. You should include citations for both direct quotes and paraphrases in the form of (Last name, Year, page number) - e.g. (Tufekci, 2017, p.180). Do not use the same wording as an author without direct quotes, and remember that just changing 1-2 words in a sentence with synonyms is not a paraphrase. Other examples of unacceptable conduct include turning in as your own work a paper written by another student who has previously taken this course, a paper you found on the Internet, or a paper you paid a commercial term-paper service to write for you. If in doubt, please ask! 

If you are feeling stress about workload and deadlines, rather than resort to such desperate measures, please come talk with one of us in office hours or over Slack to work out a plan of action for completing course requirements.

## Statement of Diversity and Inclusion:
As we discuss in this class, science (and knowledge creation more
generally) is subjective and is historically built on a small subset of privileged voices. Integrating a diverse set
of experiences is important for a more comprehensive understanding of data science.

In this class, we will make an effort to read papers from a diverse group of scholars and actively address questions
of privilege, marginality, and inclusion in data science and beyond. We would moreover like to create a learning
environment for our students that supports a diversity of thoughts, perspectives and experiences, and honors
your identities (including race, gender, class, sexuality, age, religion, ability, etc.).

To help accomplish this:
* Please let us know in the initial survey what your preferred name and pronouns are.
* You should always strive to respect the diversity of your classmates.
* If you feel like your performance in the class is being impacted by your experiences outside of class, please
come and talk with us or submit anonymous feedback via the [w231 feedback survey](https://forms.gle/yxEHyfshm8FGLgqz8) (which may lead to
me making an announcement to the class, if this is necessary to address your concerns). If you prefer to
speak with someone outside of the course, the Academic Director of Data Science, the Assistant Dean of
Academic Programs, and the [I School diversity and inclusion resource page](https://www.ischool.berkeley.edu/about/community/resources) are good places to start.
* We (like many people) am still in the process of learning about diverse perspectives and identities. If
something was said in class (by anyone, including us instructors!) that made you feel uncomfortable,
please talk to us about it. (Again, anonymous feedback is always an option via the [w231 feedback survey](https://forms.gle/yxEHyfshm8FGLgqz8).

## Class Calendar:

Synch&nbsp;Dates | Asynch<br>Week | Description | Instructor
-|-|-|-
Aug 24-26 | [Week&nbsp;1](#week-1) | Politics of Objectivity and Countercultures of Science | (Ames)
Aug 31-2 | [Week&nbsp;2](#week-2) | The Foundations of Subject Rights Online | (Ames)
&nbsp; | &nbsp; | **DUE Friday, Sep 4: [Survey](https://goo.gl/forms/Yht3jSSFUxXT8hKq2), [Blog Post Sign-ups](Assignments/0_Public_Advocacy_Blog_Post.md)**
Sep 9 | &nbsp; | SCHOLAR STRIKE (https://www.scholarstrike.com/) - extended office hours, see Slack | (Ames)
&nbsp; | &nbsp; | **DUE Friday, Sep 11: [Application of Belmont Principles](Assignments/1_Application_of_Belmont_Principles.md)**
Sep 14-16 | [Week&nbsp;3](#week-3) | The Foundations of Subject Rights for Big Data | (Ames)
Sep 21-23 | [Week&nbsp;5](#week-5) | Principles of Privacy | (Maslin)
Sep 28-30 | [Week&nbsp;6](#week-6) | Data Subjects' Rights, Rights of Others, and Institutional Obligations and Duties | (Maslin)
&nbsp; | &nbsp; | **DUE Friday, Oct 2: [Privacy Policy Assignment](Assignments/2_Privacy_Policy_Assignment.md) (slides, doc)**
Oct 5-7   | [Week&nbsp;7](#week-7) | _Presentations of Privacy Policy Assignment_ | (Maslin)
Oct 12-14 | [Week&nbsp;4](#week-4) | Categories, Categorization, and Residuality | (Ames)
Oct 19-21 | [Week&nbsp;8](#week-8) | Biases In Data and Algorithms | (Ames)
&nbsp; | &nbsp; | **DUE Wednesday, Oct 21: [Final Project Outline](Assignments/5_Final_Project_Overview.md)**
Oct 26-28 | [Week&nbsp;9](#week-9) | Mitigation and Management | (Maslin)
&nbsp; | &nbsp; | **DUE Friday, Oct 30: [Peer Feedback Assignment](Assignments/3_Peer_Feedback_Assignment.md)**
Nov 2-4   | [Week&nbsp;10](#week-10) | Exposing Commitments, Stakeholders, and Methods | (Maslin)
Nov 9-11  | NONE | **NO CLASS - FALL IMMERSION** | 
Nov 16-18 | [Week&nbsp;11](#week-11) | _Presentations of Group Legal/Ethical Analysis_ | (Maslin)
&nbsp; | &nbsp; | **DUE Friday, Nov 20: [Group Legal/Ethical Analysis](Assignments/4_Group_Legal_Ethical_Analysis.md) (slides, doc)**
Nov 23-25 | NONE | **NO CLASS - THANKSGIVING BREAK** | 
Nov 30-2  | [Week&nbsp;13](#week-13) | Organizational: Professionals and Professional Associations | (Ames)
&nbsp; | &nbsp; | **DUE Friday, Dec 4: [Final Project Presentation Sign-ups](https://goo.gl/krXaCd)**
Dec 7-9   | NONE | _Final Project Presentations - EXTENDED SESSION_ | (both)
&nbsp; | &nbsp; | **DUE Wednesday, Dec 16: [Final Project](Assignments/5_Final_Project_Overview.md) (slides, doc) - NO LATE DAYS PLEASE**

**Academic Calendar:** https://www.ischool.berkeley.edu/intranet/students/mids/calendar

## [Weekly Readings:](/Readings)

Readings for each week are linked (when availabe online) OR included in the [Readings](/Readings) directory here in GitHub. Click the week description to expand the list of readings for that week.

### [Week 1](/Readings/Unit%2001)
<details>
  <summary>Politics of Objectivity and Countercultures of Science</summary>

<br>

1. (16p) Sandra G. Harding. After the Science Question in Feminism. Introduction of _Whose Science? Whose Knowledge?: Thinking from Women's Lives_. Cornell Univ. Press, 1991. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/(w1)%20Harding.%20Whose%20Science%20Ch%201.pdf
2. (8p) Nathan Jurgenson. View From Nowhere. October 2014. https://thenewinquiry.com/view-from-nowhere/
3. (9p) Jonas Lerman. Big Data and Its Exclusions. _Stanford Law Review_ 66 (55 2013). https://doi.org/10.2139/ssrn.2293765
4. (19p) Sasha Costanza-Chock (2018). Design Justice, A.I., and Escape from the Matrix of Domination. _Journal of Design and Science._ https://doi.org/10.21428/96c8d426
5. **Case Study (for discussion)**: Familiarize yourself with Detroit's Project Green Light. Here are some resources:
   * Project Green Light website: https://detroitmi.gov/departments/police-department/project-green-light-detroit
   * Kashmir Hill. Wrongfully Accused By an Algorithm. _The New York Times_, June 24, 2020. https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html
   * Safe or Just Surveilled?: Tawana Petty on the Fight Against Facial Recognition Surveillance. _Logic Magazine_, Issue 10, May 4, 2020. https://logicmag.io/security/safe-or-just-surveilled-tawana-petty-on-facial-recognition/
6. **OPTIONAL:** Langdon Winner. Do Artifacts Have Politics? _Daedalus_ Vol. 109, No. 1, Modern Technology: Problem or Opportunity? (Winter, 1980), pp. 121-136. https://www.cc.gatech.edu/~beki/cs4001/Winner.pdf
7. **OPTIONAL:** Peggy McIntosh. White Privilege: Unpacking the Invisible Knapsack. https://racialequitytools.org/resourcefiles/mcintosh.pdf 
8. **OPTIONAL:** Kimberle Crenshaw. Demarginalizing the Intersection of Race and Sex: A Black Feminist Critique of Antidiscrimination Doctrine, Feminist Theory and Antiracist Politics. _The University of Chicago Legal Forum 139_ (1989), 139–168. https://chicagounbound.uchicago.edu/uclf/vol1989/iss1/8
</details>

### [Week 2](/Readings/Unit%2002)
<details>
  <summary>The Foundations of Subject Rights Online</summary>

<br>

1. (12p) The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research. The Belmont Report: Ethical Principles and Guidelines for the Protection of Human Subjects of Research. April 18, 1979. https://www.hhs.gov/ohrp/sites/default/files/the-belmont-report-508c_FINAL.pdf
2. (5p) **READ 1-2, 9-11** Jessica Vitak, Katie Shilton, and Zahra Ashktorab. 2016. Beyond the Belmont Principles: Ethical Challenges, Practices, and Beliefs in the Online Data Research Community. _Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing (CSCW '16)_, 941–953. https://doi.org/10.1145/2818048.2820078
3. (2p) **READ 11-12, SKIM THE REST** D. Dittrich and E. Kenneally, "The Menlo Report: Ethical Principles Guiding Information and Communication Technology Research", Tech. Report, U.S. Department of Homeland Security, Aug 2012. https://www.caida.org/publications/papers/2012/menlo_report_actual_formatted/
4. (11p) Mark A Rothstein and Abigail B Shoben. Does consent bias research? _American Journal of Bioethics_ 13.4 (Apr. 2013). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2244990
5. (19p) Benbunan-Fich, R. (2017). The ethics of online research with unsuspecting users: From A/B testing to C/D experimentation. _Research Ethics,_ 13(3–4), 200–218. https://doi.org/10.1177/1747016116680664
6. (22p) Selinger, Evan and Hartzog, Woodrow, _The Inconsentability of Facial Surveillance_ (March 19, 2020). _66 Loyola Law Review_ 101 (2019). https://ssrn.com/abstract=3557508, also available at https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Selinger%20and%20Hartzog.%20The%20Inconsentability%20of%20Facial%20Recognition.pdf
7. **OPTIONAL:** Declaration of Helsinki - Ethical Principles for Medical Testing involving Human Subjects. https://wma.net/policies-post/wma-declaration-of-helsinki-ethical-principles-for-medical-research-involving-human-subjects/
</details>

### [Week 3](/Readings/Unit%2003)
<details>
  <summary>The Foundations of Subject Rights for Big Data</summary>

<br>

1. (60p) **SKIM Summary and Recommendations, Chapters 3-4** Records, Computers and the Rights of Citizens ("The HEW Report"). Government Printing Office, 1973. http://www.justice.gov/sites/default/files/opcl/docs/rec-com-rights.pdf
2. (18p) William Seltzer (2006). The Dark Side of Numbers: Updated. Mackensen R. (eds), _Bevölkerungsforschung und Politik in Deutschland im 20. Jahrhundert. VS Verlag für Sozialwissenschaften._ https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/(w3)%20Seltzer.%20Dark%20Side%20of%20Numbers%20Updated.pdf
3. (2p) Kate Crawford. Hidden Biases in Big Data. _Harvard Business Review_ (2013). https://hbr.org/2013/04/the-hidden-biases-in-big-data
4. (11p) Jacob Metcalf and Kate Crawford. Where are human subjects in Big Data research? The emerging ethics divide. _Big Data & Society_ (2016). https://journals.sagepub.com/doi/full/10.1177/2053951716650211
5. (4p) Fair Information Practice Principles (FIPPs) in the Information Sharing Environment. https://nationalpublicsafetypartnership.org/Documents/The_Fair_Information_Practice_Principles_in_the_Information_Sharing_Environment.pdf
6. **OPTIONAL:** Office of Privacy and Civil Liberties (OPCL), Department of Justice. Overview of the Privacy Act of 1974, 2015 Edition. https://www.justice.gov/opcl/overview-privacy-act-1974-2015-edition

</details>

### [Week 4](/Readings/Unit%2004)
<details>
  <summary>Categories, Categorization, and Residuality</summary>
 
<br>

1. (26p) Geoffrey C. Bowker and Susan Leigh Star. What a Difference a Name Makes - The Classification of Nursing Work. Chapter 7 of _Sorting Things Out: Classification and its Consequences_. MIT Press, 1999. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Bowker%20and%20Star.%20Sorting%20things%20Out%20ch7.pdf
2. (36p) David Kertzer and Dominique Arel. Censuses, Identity Formation, and the Struggle for Political Power. Chapter 1 of _Census and Identity: The Politics of Race, Ethnicity, and Language in National Censuses_. Cambridge University Press, 2002. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Kertzer%20and%20Arel.%20%20Census%20and%20Identity%20ch1.pdf
3. (11p) Bonnie Ruberg and Spencer Ruelos. Data for Queer Lives: How LGBTQ Gender and Sexuality Identities Challenge Norms of Demographics. _Big Data & Society_, June 2020, https://journals.sagepub.com/doi/full/10.1177/2053951720933286
4. **OPTIONAL** Kate Crawford and Trevor Paglen. Excavating AI: The Politics of Training Sets for Machine Learning. September 19, 2019 (analysis accompanying the ImageNet Roulette demo). https://excavating.ai
5. **OPTIONAL** David Valentine. The Categories Themselves. _GLQ: A Journal of Lesbian and Gay Studies,_ 10.2 (Jan. 2004), 215–220. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Valentine.%20The%20Categories%20Themselves.pdf
</details>

### [Week 5](/Readings/Unit%2005)
<details>
  <summary>Principles of Privacy</summary>

<br>

1. (7p) **READ 479-483, 490-491** Solove, Daniel J. (2006). A Taxonomy of Privacy. _University of Pennsylvania Law Review,_ 154:3 (January 2006), p. 477. https://ssrn.com/abstract=667622
2. (14p) Nissenbaum, Helen F. (2011). A Contextual Approach to Privacy Online. _Daedalus_ 140:4 (Fall 2011), 32-48. https://ssrn.com/abstract=2567042
3. (16p) Mulligan, Deirdre K., Koopman, Colin and Doty, Nick (2016). Privacy is an essentially contested concept: a multi-dimensional analytic for mapping privacy. _Philosophical Transactions of The Royal Society A: Mathematical Physical and Engineering Sciences_, 374(2083):20160118 (December 2016). http://doi.org/10.1098/rsta.2016.0118
4. (25p) **READ 1099-1123** Solove, Daniel J. (2002). Conceptualizing Privacy. _California Law Review_ 90.4 (July 2002). https://doi.org/10.15779/Z382H8Q
5. **OPTIONAL** A. Acquisti, L. Brandimarte, and G. Loewenstein. Privacy and human behavior in the age of information. _Science_ 347.6221 (Jan. 2015), pp. 509–514. https://doi.org/10.1126/science.aaa1465.
</details>

### [Week 6](/Readings/Unit%2006)
<details>
  <summary>Data Subjects' Rights, Rights of Others, and Institutional Obligations and Duties</summary>

<br>

1. (22p) **READ Chapter 1 (13-17), Chapter 2 (19-35).** The OECD Privacy Framework (2013 update on 1980 report). http://www.oecd.org/sti/ieconomy/oecd_privacy_framework.pdf
2. (34p) **SKIM** Data Guidance and Future of Privacy Forum. Comparing Privacy Laws: GDPR v. CCPA. https://fpf.org/wp-content/uploads/2018/11/GDPR_CCPA_Comparison-Guide.pdf
3. (11p) **READ 1-2, SKIM rest** Federal Reserve. Federal Trade Commission Act Section 5: Unfair or Deceptive Acts or Practices. _Consumer Compliance Handbook._ https://www.federalreserve.gov/boarddocs/supmanual/cch/ftca.pdf
4. (~7p) A Brief Overview of the Federal Trade Commission's Investigative, Law Enforcement, and Rulemaking Authority. 
https://www.ftc.gov/about-ftc/what-we-do/enforcement-authority
5. **OPTIONAL** Federal Trade Commission Act. https://www.ftc.gov/sites/default/files/documents/statutes/federal-trade-commission-act/ftc_act_incorporatingus_safe_web_act.pdf
6. **OPTIONAL** Guidelines on the Right to Data Portability. https://ec.europa.eu/information_society/newsroom/image/document/2016-51/wp242_en_40852.pdf
7. **OPTIONAL** Data Portability FAQ. https://ec.europa.eu/information_society/newsroom/image/document/2016-51/wp242_annex_en_40854.pdf
8. **SKIM - discussed in asynch** In re Facebook, Complaint, FTC File No. 092 3184. 2012.
9. **SKIM - discussed in asynch** In the Matter of ELI LILLY and COMPANY, a corporation. 2002.
</details>

### [Week 7](/Readings/Unit%2007)
<details>
  <summary>Science of Privacy</summary>

<br>

1. (9p) Arvind Narayanan and Edward W. Felten. No silver bullet: De-identification still doesn't work. https://www.cs.princeton.edu/~arvindn/publications/no-silver-bullet-de-identification.pdf
2. Cynthia Dwork. Differential Privacy. _33rd International Colloquium on Automata, Languages and Programming,_ part II (ICALP 2006). Vol. 4052. Venice, Italy: Springer Verlag, July 2006, pp. 1–12. https://www.microsoft.com/en-us/research/publication/differential-privacy/
3. Ryan Calo and Alex Rosenblat. The Taking Economy: Uber, Information, and Power (2017). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2929643
4. Bernardo A Huberman, Eytan Adar, and Leslie R Fine. Valuating Privacy. _IEEE Security & Privacy_ (Oct. 2005), pp. 22–25. https://doi.org/10.1109/MSP.2005.137
5. **OPTIONAL:** Serge Egelman, Adrienne Porter Felt, and David Wagner. Choice Architecture and Smartphone Privacy: There's a Price for That. _The Economics of Information Security and Privacy_ (2013), pp. 211–236. https://doi.org/10.1007/978-3-642-39498-0_10
6. **OPTIONAL:** Janice Y. Tsai et al. The Effect of Online Privacy Information on Purchasing Behavior: An Experimental Study. _Information Systems Research_ 22.2 (June 2011), pp. 254–268. https://doi.org/10.1287/isre.1090.0260
7. **OPTIONAL:** Sarah Spiekermann, Jens Grossklags, and Bettina Berendt. E-privacy in 2nd generation E-commerce. _Proceedings of the 3rd ACM conference on Electronic Commerce_ (Oct. 2001). https://doi.org/10.1145/501158.501163
8. **OPTIONAL:** Fida Kamal Dankar and Khaled El Emam. Practicing differential privacy in health care: A review. _Trans. Data Privacy_ 6.1 (2013), pp. 35–67.
9. **OPTIONAL:** Luc Rocher, Julien M. Hendrickx and Yves-Alexandre de Montjoye. Estimating the success of re-identifications in incomplete datasets using generative models. _Nature Communications_ volume 10, Article number: 3069 (2019). https://www.nature.com/articles/s41467-019-10933-3

</details>

### [Week 8](/Readings/Unit%2008)
<details>
  <summary>Biases In Data and Algorithms</summary>

<br>

1. Tarleton Gillespie. The Relevance of Algorithms. _Media Technologies_ (2014), pp. 167–194. https://doi.org/10.7551/mitpress/9780262525374.003.0009f
2. Felicitas Kraemer, Kees van Overveld, and Martin Peterson. Is there an ethics of algorithms? _Ethics and Information Technology_ 13.3 (Sept. 2011), pp. 251–260.
3. Jenna Burrell. How the machine thinks: Understanding opacity in machine learning algorithms. _Big Data & Society_ 3.1 (2016). https://doi.org/10.1177/2053951715622512
5. FTC. Big Data: A Tool for Inclusion or Exclusion? Understanding the Issues (READ: executive summary and questions for legal compliance). https://www.ftc.gov/system/files/documents/reports/big-data-tool-inclusion-or-exclusion-understanding-issues/160106big-data-rpt.pdf
6. Jonas Lehrman. Big Data and Its Exclusions. _Stanford Law Review_ 66 (55 2013). https://doi.org/10.2139/ssrn.2293765
7. Cynthia Dwork and Deirdre K Mulligan. It's not privacy, and it's not fair. _Stanford Law Review_ (Sept. 2013). https://www.stanfordlawreview.org/online/privacy-and-big-data-its-not-privacy-and-its-not-fair/
8. **SKIM** United States of America (for the Federal Trade Commission) v. Spokeo Inc., Civ. No. CV12-05001. 2012.
9. **OPTIONAL:**  Karen Hao and Jonathan Stray. Can you make AI fairer than a judge? Play our courtroom algorithm game. _MIT Technology Review_, October 17, 2019. https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/
</details>

### [Week 9](/Readings/Unit%2009)
<details>
  <summary>Mitigation and Management</summary>

<br>

1. NIST. Privacy Framework Factsheet. 2020. https://www.nist.gov/privacy-framework/privacy-framework
2. Privacy Office. Privacy Impact Assessment. Department of Homeland Security, 2014. https://www.dhs.gov/compliance
3. TSA and Robin Kane. Privacy Impact Assessment Update for TSA Whole Body Imaging. Department of Homeland Security, 2009. https://data.aclum.org/wp-content/uploads/2018/06/Priv-Impact-Assessment-Update-for-TSA-Whole-Body-Imaging-7-23-2009.pdf
4. Charles Raab and David Wright. Surveillance: Extending the Limits of Privacy Impact Assessment. https://doi.org/10.1007/978-94-007-2543-0_17
5. Joe Sharkey. A Farewell to 'Nudity' at Airport Checkpoints. _The New York Times_ (Jan. 2013). http://www.nytimes.com/2013/01/22/business/a-farewell-to-nudity-at-airport-checkpoints.html
6. Katie Rogers. T.S.A. Defends Treatment of Transgender Air Traveler. _The New York Times_ (Sept. 2015). https://www.nytimes.com/2015/09/23/us/shadi-petosky-tsa-transgender.html
</details>

### [Week 10](/Readings/Unit%2010)
<details>
  <summary>Exposing Commitments, Stakeholders, and Methods</summary>

<br>

1. Danielle Keats Citron. Technical Due Process. _Washington University Law Review_ 85 (2007). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1012360
2. Kate Crawford and Jason Schultz. Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms. _Boston College Law Review_ 55.93 (2014). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2325784
3. Tad Hirsch et al. Designing Contestability: Interaction Design, Machine Learning, and Mental Health. _Proceedings of the 2017 Conference on Designing Interactive Systems_ (2017), pp. 95–99. https://doi.org/10.1145/3064663.3064703
4. Mulligan, Deirdre K. and Kluttz, Daniel and Kohli, Nitin. Shaping Our Tools: Contestability as a Means to Promote Responsible Algorithmic Decision Making in the Professions (July 7, 2019). http://dx.doi.org/10.2139/ssrn.3311894
</details>

### [Week 11](/Readings/Unit%2011)
<details>
  <summary>Additional Legal Limitations of Data: Copyright, Contracts, and Database Rights</summary>

<br>

1. Copyright Act 102, 106(a), 107. https://www.copyright.gov/title17/92chap1.html#102
2. Computer Fraud and Abuse Act, 18 USC. https://www.law.cornell.edu/uscode/text/18/1030.
3. CalECPA (state bill 178). https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=201520160SB178.
4. **SKIM** Facebook v. Vachani & Power Ventures. July 2016. https://cdn.ca9.uscourts.gov/datastore/opinions/2016/07/12/13-17102.pdf
5. **SKIM** Feist Pubs., Inc. v. Rural Tel. Svc. Co., Inc. 499 U.S. 340 (1991). 1991. https://scholar.google.com/scholar_case?case=1195336269698056315
6. **SKIM** ProCD, INC. v. ZEIDENBERG, 86 F.3d 1447 (7th. Cir. 1996). 1996. https://scholar.google.com/scholar_case?case=11811009805458694240
</details>

### [Week 13](/Readings/Unit%2012)
<details>
  <summary>Organizational: Professionals and Professional Associations</summary>

<br>

1. Alex Fowler. Do Not Track: It's the user's voice that matters. May 2012. https://blog.mozilla.org/netpolicy/2012/05/31/do-not-track-its-the-users-voice-that-matters/
2. Tracking Preference Expression (DNT). https://www.w3.org/TR/tracking-dnt/
3. Allison Grande. Do-Not-Track Group Finally Nails Down Tech Standard. _Law360 - The Newswire for Business Lawyers_ (2014). https://www.law360.com/articles/531445.
4. Elon Musk. A Most Peculiar Test Drive. Feb. 2013. https://www.tesla.com/blog/most-peculiar-test-drive
5. Kashmir Hill. The Big Privacy Takeaway From Tesla vs. The New York Times. Feb. 2013. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/The%20Big%20Privacy%20Takeaway%20From%20Tesla%20vs.%20The%20New%20York%20Times.pdf
6. Tesla Motors. Privacy Statement. June 2013. https://www.tesla.com/sites/default/files/pdfs/tmi_privacy_statement_external_6-14-2013_v2.pdf
</details>


