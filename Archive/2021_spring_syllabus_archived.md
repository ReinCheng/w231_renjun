# Behind the Data: Humans and Values | Spring 2021

This syllabus is a living document, and is subject to change throughout the semester. Please always check the version in the class GitHub repo (https://github.com/UC-Berkeley-I-School/w231) for the latest updates.

**Instructors:**  
* Morgan Ames, morganya@berkeley.edu
* Jared Maslin, jfmyq9@berkeley.edu

**TA:** Kai Nham, knham+w231@berkeley.edu

**Synchronous Section Times:** 
* Tuesdays and Wednesdays, 4-5:30pm PT

**Office Hours** are the hour before synch sessions, or by appointment, in Zoom.

## Course Description:
This course provides an introduction to the legal, policy, and ethical implications of data. The course will examine how these issues arise throughout the full life cycle of data science from collection, to storage, processing, analysis and use including, privacy, surveillance, security, classification, discrimination, decisional autonomy, and duties to warn or act. Case studies will be used to explore these issues across various domains such as criminal justice, national security, health, marketing, politics, education, automotive, employment, athletics, and development. Attention will be paid to legal and policy constraints and considerations that attach to specific domains as well as particular data-types, collection methods, and institutions. Technical, legal, and market approaches to mitigating and managing discrete and compound sets of concerns will be introduced, and the strengths and benefits of competing and complementary approaches will be explored. **Prerequisites:** Students must complete MIDS courses 201 and 203 before enrolling in this course.

## Links to Course Pages: 
1. Course Github: https://github.com/UC-Berkeley-I-School/w231
2. Course Blog: https://blogs.ischool.berkeley.edu/w231/
3. Course Slack Channel: [#w231-announce](https://app.slack.com/client/T0WA5NWKG/C6WKWFVR6)
4. Course Signup sheets:
   * Introductory Survey: https://goo.gl/forms/Yht3jSSFUxXT8hKq2
   * Public Advocacy Blog Assignment Sign-Ups: https://goo.gl/6uZY62
   * Final Project Presentation Sign-Ups: https://goo.gl/krXaCd
   * Anonymous Course Feedback: https://forms.gle/yxEHyfshm8FGLgqz8

## Course Evaluation:
* Participation (25%)
  * Synchronous session discussion (15%). Attend and actively participate in every synchronous session.
  * Asynchronous participation (10%). This class relies on readings and asynch content. Both are necessary for the synch session, and are important for the course. Complete both before the synch session each week. 
* [Assignments](Assignments) (40%):
  * Descriptions are in the Assignments folder in the class git repository, and linked from here. All assignments are due 11:59pm Pacific Time (PT) on the date noted, in ISVC unless otherwise indicated in the assignment description. Please convert docx and pptx files to pdf.
  * [Application of Belmont Principles](Assignments/1_Application_of_Belmont_Principles.md) (8%)
  * [Privacy Policy Assignment](Assignments/2_Privacy_Policy_Assignment.md) (8%)
  * [Peer Feedback Assignment](Assignments/3_Peer_Feedback_Assignment.md) (8%)
  * [Group Legal/Ethical Analysis](Assignments/4_Group_Legal_Ethical_Analysis.md) (8%)
  * [Public Advocacy Blog Post](Assignments/0_Public_Advocacy_Blog_Post.md) (8%)
* [Final Project](Assignments/5_Final_Project_Overview.md) (35%): 5% outline, 30% final write-up

**Assignment Late Policy:** If you cannot make a deadline, contact us as soon as you can to make a plan for an alternate due date. We offer five floating late days penalty-free, but beyond those five days late assignments may be docked up to 5 percent per day late. 

**Effective Reading Strategies:** While this course that would be considered reading-moderate in the humanities or social sciences (where it is common to have weekly reading loads of several hundred pages per course at the graduate level, and well over 100 even at the undergraduate level), I recognize that many of you come from technical backgrounds and may not be accustomed to this kind of workload. This Berkeley guide for reading in the social sciences (https://gsi.berkeley.edu/gsi-guide-contents/critical-reading-intro/social-science/) suggests a four-pass approach which I have replicated below to as one way to make this more tractable. We are also happy to discuss other strategies in class or office hours.
1. First Reading: Previewing. The first time you read a text, skim it quickly for its main ideas. Pay attention to the introduction, the opening sentences of paragraphs, and section headings, if there are any. Previewing the text in this way gets you off to a good start when you have to read critically.
1. Second Reading: Annotating and Analyzing. The second reading includes annotating and analyzing the evidence in support of the argument. It should be a slow, meditative read, and you should have your pencil in your hand so you can annotate the text. Taking time to annotate your text during the second reading may be the most important strategy to master if you want to become a critical reader.
1. Third Reading: Review. The third reading should take into account any questions you asked yourself by annotating in the margins. You should use this reading to look up any unfamiliar words and to make sure you have understood any confusing or complicated sections of the text.
1. Fourth Step: Responding. Responding to what you read is an important step in understanding what you read. You can respond in writing or by talking about what you’ve read to others. _(Note that the weekly writing prompts and class discussions are designed to help you with this.)_

**Writing Practices:** This course is focused on not only teaching you about the human values and ethical implications of data science, but to communicate effectively about what you've learned. As such, the assignments (as well as the course discussions) are focused on giving you lots of practice clearly stating your position and backing it up using course materials and other evidence. Throughout, please strive to:
* Clearly and accurately reference the argument/arguments of the readings you are drawing on, using your own words and without merely quoting.
* Take a position on this argument, but do so in a way that uses sound logic or credible evidence to support your position. You should avoid referencing personal experiences as 'proof' - stick to what is stated in the readings or other evidence-based sources.

The purpose of writing is to engage with and think about the course materials and to practice communicating clearly and persuasively. Writing about a topic is a great way to think deeply about it. In particular, the reading responses provide an opportunity to work on thinking _critically_ about technology and information systems, the role they play, and influence they have in society. _What does it mean to think critically?_ This does not mean simply to be negative, to harbor dystopian views about technology, or to be a pessimist, or a luddite, or a crank. It does mean being skeptical. It means considering the evidence presented and its strengths and weaknesses. It means examining the arguments being made and their logic. It means being willing to examine your own assumptions, biases, and blindspots and potentially to change your mind in the face of strong evidence.

**Citation Practices:** When writing analytically you will often draw upon the ideas and arguments of others to develop your own analysis. It’s important to distinguish your own ideas from the ideas of others. A mistake some students make is to assume that there is one correct or optimal answer to an essay question and that the sequence of words for a correct answer cannot be “owned” by anyone. To the contrary, writing in your own words is part of thoroughly absorbing ideas and transforming them into your tools of analysis. On ethical grounds proper citation practices mean giving credit to those who’ve come up with the ideas and arguments you are borrowing from.

Avoiding inadvertent plagiarism starts with good note-taking practices. Make sure to keep notes on sources. When you write down (or copy and paste) something word-for-word from a reading into your own note-taking files, put it in double quotes (“”) and note the source and page number. This will make for easier work later on when you draw from your notes while writing up your assignments.

Citing involves two components:
1. **In-text citations** – where you indicate the source of an idea or quote in the body of your essay. In-text citations should look like this: (Author year). An in-text citation is placed at the end of the sentence. Here’s an example: _Women's uses of the telephone in the early 20th century went against the intentions of designers (Fischer 1992)._ For multiple citations, separate with semicolons, and where there are two authors, list both authors’ last names. For three or more authors, list the first author’s last name and follow with ‘et al.’ Here are examples: (Ames 2019; Oreglia and Geiger 2009; Srinivasan et al. 2000). Be very sure to put word-for-word references to texts in double quotes (“”) and include an in-text citation with page number in the form of (AUTHOR year: pg#), e.g. (Ames 2019: 54). Please note that extensive paraphrasing where you change a few words in a sentence or paragraph from a published source but leave it essentially the same is plagiarism and not acceptable. Furthermore, wholesale borrowing of the larger structure, argument, and evidence of a published piece is also plagiarism.
1. **A list of references** – at the end of your document, where you list the full details for any source that you’ve used.mA reference to each cited text should be placed in the references section at the end of your written piece. The references should include the names of all authors, the title of the cited piece, year of publication, volume and issue numbers (for periodicals), page numbers (for periodicals and book chapters in edited books), publisher name and city (for books). APA or MLA format are widespread standards that you can easily find online. See the library source page on this: http://www.lib.berkeley.edu/instruct/guides/citations.html. If you are citing online resources, here are some guidelines on how to do so: http://www.lib.berkeley.edu/MRC/mla.html#online. If there are pieces of information that are missing (for example, a clear author), you should at the very least have the title of the page, the url, and the date when you visited it.

**A Note on Plagiarism:** Some cases of plagiarism stem from a poor understanding of how and when to cite sources. We will clarify expectations and best practices up front at the beginning of the semester. In addition, we expect all students to abide by the Berkeley Student Code of Conduct (see http://students.berkeley.edu/uga/conduct.pdf). Cases of plagiarism will not be tolerated. The consequences include failing the assignment, a referral to the Center for Student Conduct and Community Standards, possibly a failed grade in the course, and even expulsion from the program. 

Plagiarism includes copying material from a book or article (word-for-word or paraphrased) without citing the source as well as extensively summarizing the written work of someone else without clarifying that the ideas and analysis are not your own. You should include citations for both direct quotes and paraphrases in the form of (Last name, Year, page number) - e.g. (Tufekci, 2017, p.180). Do not use the same wording as an author without direct quotes, and remember that just changing 1-2 words in a sentence with synonyms is not a paraphrase. Other examples of unacceptable conduct include turning in as your own work a paper written by another student who has previously taken this course, a paper you found on the Internet, or a paper you paid a commercial term-paper service to write for you. If in doubt, please ask! 

If you are feeling stress about workload and deadlines, rather than resort to such desperate measures, please come talk with one of us in office hours or over Slack to work out a plan of action for completing course requirements.

## Statement of Diversity and Inclusion:
As we discuss in this class, science (and knowledge creation more
generally) is subjective and is historically built on a small subset of privileged voices. Integrating a diverse set
of experiences is important for a more comprehensive understanding of data science, and is central to the values and purposes of this class.

We've put together a syllabus that includes rigorous and groundbreaking work from a wide diversity of scholars, and that actively addresses questions
of privilege, marginality, and inclusion in data science and beyond. We would moreover like to create a learning
environment for our students that supports a diversity of perspectives and experiences, honors
your identities (including race, gender, class, sexuality, age, religion, ability, etc.), and feels safe for all.

To help accomplish this:
* Please let us know in the initial survey what your preferred name and pronouns are.
* You should always strive to respect your classmates and create a safe space for learning and discussion.
* If you feel like your performance in the class is being impacted by your experiences outside of class, please
come and talk with us or submit anonymous feedback via the [w231 feedback survey](https://forms.gle/yxEHyfshm8FGLgqz8) (which may lead to
me making an announcement to the class, if this is necessary to address your concerns). If you prefer to
speak with someone outside of the course, the Academic Director of Data Science, the Assistant Dean of
Academic Programs, and the [I School diversity and inclusion resource page](https://www.ischool.berkeley.edu/about/community/resources) are good places to start.
* We do our best, but we (like many people) are still in the process of learning about diverse perspectives and identities. If
something was said in class (by anyone, including us instructors!) that made you feel uncomfortable,
please talk to us about it. (Again, anonymous feedback is always an option via the [w231 feedback survey](https://forms.gle/yxEHyfshm8FGLgqz8)).

## Class Calendar:

&nbsp;&nbsp;Week&nbsp; | Asynch<br>Unit | Description | Instructor
-|-|-|-
Jan 4 | [Unit&nbsp;1](#unit-1) | Politics of Objectivity and Countercultures of Science | (Ames)
Jan 11 | [Unit&nbsp;2](#unit-2) | The Foundations of Subject Rights Online | (Ames)
&nbsp; | &nbsp; | **DUE Friday, Jan 15: [Survey](https://goo.gl/forms/Yht3jSSFUxXT8hKq2), [Blog Post Sign-ups](Assignments/0_Public_Advocacy_Blog_Post.md)**
Jan 18 | [Unit&nbsp;3](#unit-3) | The Foundations of Subject Rights for Big Data | (Ames)
&nbsp; | &nbsp; | **DUE Friday, Jan 22: [Application of Belmont Principles](Assignments/1_Application_of_Belmont_Principles.md)**
Jan 25 | [Unit&nbsp;4](#unit-4) | Categories, Categorization, and Residuality | (Ames)
Feb 1 | [Unit&nbsp;5](#unit-5) | Frameworks for Analyzing Privacy | (Maslin)
Feb 8 | [Unit&nbsp;6](#unit-6) | The Shifting Sands of Privacy Protection Regulation | (Maslin)
&nbsp; | &nbsp; | **DUE Friday, Feb 12: [Privacy Policy Assignment](Assignments/2_Privacy_Policy_Assignment.md) (slides, doc)**
Feb 15 | [Unit&nbsp;7](#unit-7) | _Presentations of Privacy Policy Assignment_ | (Maslin)
Feb 22 | [Unit&nbsp;8](#unit-8) | Algorithmic Bias and Opacity | (Ames)
Mar 1 | [Unit&nbsp;9](#unit-9) | Due Process and Consumer Protections with Big Data | (Maslin)
&nbsp; | &nbsp; | **DUE Wednesday, Mar 3: [Final Project Outline](Assignments/5_Final_Project_Overview.md)**
Mar 8 | [Unit&nbsp;10](#unit-10) | Impact Assessments and Other Institutional Approaches to Data Science Ethics | (Maslin)
&nbsp; | &nbsp; | **DUE Friday, Mar 12: [Peer Feedback Assignment](Assignments/3_Peer_Feedback_Assignment.md)**
Mar 15 | [Unit&nbsp;11](#unit-11) | Additional Legal Limitations of Data | (Maslin)
Mar 22 | NONE | **NO CLASS - SPRING BREAK** | 
Mar 29 | [Unit&nbsp;12](#unit-12) | _Presentations of Group Legal/Ethical Analysis_ | (both)
&nbsp; | &nbsp; | **DUE Friday, Apr 2: [Group Legal/Ethical Analysis](Assignments/4_Group_Legal_Ethical_Analysis.md) (slides, doc)**
Apr 5 | [Unit&nbsp;13](#unit-13) | Power and Countervailance | (Ames)
&nbsp; | &nbsp; | **DUE Friday, Apr 9: [Final Project Presentation Sign-ups](https://goo.gl/krXaCd)**
Apr 12 | NONE | _Final Project Presentations - EXTENDED SESSION_ | (both)
&nbsp; | &nbsp; | **DUE Wednesday, Apr 21: [Final Project](Assignments/5_Final_Project_Overview.md) (slides, doc) - NO LATE DAYS PLEASE**

**Academic Calendar:** https://www.ischool.berkeley.edu/intranet/students/mids/calendar

## Weekly Readings:

Readings for each week are linked (when availabe online) OR included in the [Readings](https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings) directory here in GitHub. In either case, we've included a link directly to the reading; if you have any trouble accessing any of them, please let us know! (Sometimes we mess up, and sometimes resources that were once freely available get put behind a paywall or are taken down.) Click the week description to expand the list of readings for that week.

### Unit 1
<details>
  <summary>Politics of Objectivity and Countercultures of Science</summary>

<br>

1. (16p) Sandra G. Harding. After the Science Question in Feminism. Introduction of _Whose Science? Whose Knowledge?: Thinking from Women's Lives_. Cornell Univ. Press, 1991. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/(w1)%20Harding.%20Whose%20Science%20Ch%201.pdf
1. (8p) Nathan Jurgenson. View From Nowhere. October 2014. https://thenewinquiry.com/view-from-nowhere/
1. (9p) Jonas Lerman. Big Data and Its Exclusions. _Stanford Law Review_ 66 (55 2013). https://doi.org/10.2139/ssrn.2293765
1. (19p) Sasha Costanza-Chock (2018). Design Justice, A.I., and Escape from the Matrix of Domination. _Journal of Design and Science._ https://doi.org/10.21428/96c8d426
1. **Case Study (for discussion)**: Familiarize yourself with Detroit's Project Green Light. Here are some resources:
   * Project Green Light website: https://detroitmi.gov/departments/police-department/project-green-light-detroit
   * Kashmir Hill. Wrongfully Accused By an Algorithm. _The New York Times_, June 24, 2020. https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html
   * Safe or Just Surveilled?: Tawana Petty on the Fight Against Facial Recognition Surveillance. _Logic Magazine_, Issue 10, May 4, 2020. https://logicmag.io/security/safe-or-just-surveilled-tawana-petty-on-facial-recognition/
1. **OPTIONAL** Langdon Winner. Do Artifacts Have Politics? _Daedalus_ Vol. 109, No. 1, Modern Technology: Problem or Opportunity? (Winter, 1980), pp. 121-136. https://www.cc.gatech.edu/~beki/cs4001/Winner.pdf
1. **OPTIONAL** Kimberle Crenshaw. Demarginalizing the Intersection of Race and Sex: A Black Feminist Critique of Antidiscrimination Doctrine, Feminist Theory and Antiracist Politics. _The University of Chicago Legal Forum 139_ (1989), 139–168. https://chicagounbound.uchicago.edu/uclf/vol1989/iss1/8
1. **OPTIONAL** Peggy McIntosh. White Privilege: Unpacking the Invisible Knapsack. https://racialequitytools.org/resourcefiles/mcintosh.pdf 
</details>

### Unit 2
<details>
  <summary>The Foundations of Subject Rights Online</summary>

<br>

1. (12p) The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research. The Belmont Report: Ethical Principles and Guidelines for the Protection of Human Subjects of Research. April 18, 1979. https://www.hhs.gov/ohrp/sites/default/files/the-belmont-report-508c_FINAL.pdf
1. (5p) **READ 1-2, 9-11** Jessica Vitak, Katie Shilton, and Zahra Ashktorab. 2016. Beyond the Belmont Principles: Ethical Challenges, Practices, and Beliefs in the Online Data Research Community. _Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing (CSCW '16)_, 941–953. https://terpconnect.umd.edu/~kshilton/pdf/VitaketalCSCWpreprint.pdf
1. (2p) **READ 11-12, SKIM THE REST** D. Dittrich and E. Kenneally, "The Menlo Report: Ethical Principles Guiding Information and Communication Technology Research", Tech. Report, U.S. Department of Homeland Security, Aug 2012. https://www.caida.org/publications/papers/2012/menlo_report_actual_formatted/
1. (11p) Mark A Rothstein and Abigail B Shoben. Does consent bias research? _American Journal of Bioethics_ 13.4 (Apr. 2013). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2244990
1. (19p) Benbunan-Fich, R. (2017). The ethics of online research with unsuspecting users: From A/B testing to C/D experimentation. _Research Ethics,_ 13(3–4), 200–218. https://doi.org/10.1177/1747016116680664
1. (22p) Selinger, Evan and Hartzog, Woodrow, _The Inconsentability of Facial Surveillance_ (March 19, 2020). _66 Loyola Law Review_ 101 (2019). https://ssrn.com/abstract=3557508, also available at https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Selinger%20and%20Hartzog.%20The%20Inconsentability%20of%20Facial%20Recognition.pdf
1. **Case Study (for discussion)**: familiarize yourself with one controversial online research study or similar event you have heard about in the news over the last few years that might have had issues with consent, justice, data disclosure, etc. Cambridge Analytica, Compas, PredPol, and Clearview.AI are some examples - but there are many other possibilities! For some ideas, you can look at https://medium.com/@AINowInstitute/ai-in-2018-a-year-in-review-8b161ead2b4e or https://github.com/daviddao/awful-ai. 
1. **OPTIONAL** Declaration of Helsinki - Ethical Principles for Medical Testing involving Human Subjects. https://wma.net/policies-post/wma-declaration-of-helsinki-ethical-principles-for-medical-research-involving-human-subjects/
</details>

### Unit 3
<details>
  <summary>The Foundations of Subject Rights for Big Data</summary>

<br>

1. (60p) **SKIM Summary and Recommendations, Chapters 3-4** Records, Computers and the Rights of Citizens ("The HEW Report"). Government Printing Office, 1973. http://www.justice.gov/sites/default/files/opcl/docs/rec-com-rights.pdf
1. (18p) William Seltzer (2006). The Dark Side of Numbers: Updated. Mackensen R. (eds), _Bevölkerungsforschung und Politik in Deutschland im 20. Jahrhundert. VS Verlag für Sozialwissenschaften._ https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/(w3)%20Seltzer.%20Dark%20Side%20of%20Numbers%20Updated.pdf
1. (2p) Kate Crawford. Hidden Biases in Big Data. _Harvard Business Review_ (2013). https://hbr.org/2013/04/the-hidden-biases-in-big-data
1. (11p) Jacob Metcalf and Kate Crawford. Where are human subjects in Big Data research? The emerging ethics divide. _Big Data & Society_ (2016). https://journals.sagepub.com/doi/full/10.1177/2053951716650211
1. (4p) Fair Information Practice Principles (FIPPs) in the Information Sharing Environment. https://nationalpublicsafetypartnership.org/Documents/The_Fair_Information_Practice_Principles_in_the_Information_Sharing_Environment.pdf
1. **Case Study (for discussion)**: DTC genetic testing
   * https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3767220/ - look in particular at some of the concerns about DTC genetic testing in this article
   * https://wired.com/story/theres-no-such-thing-as-family-secrets-in-the-age-of-23andme/ - provides more background about the ups and downs of DTC genetic testing, and the kinds of family secrets these tests have uncovered.
   * **SKIM** https://wired.com/story/dna-transfer-framed-murder/ - this is a case study of DNA identification gone wrong. Content warning: description of violent robbery; skip to the paragraph above the first inline photo of the public defender if you want to avoid it.
   * **SKIM** https://nytimes.com/2019/11/05/business/dna-database-search-warrant.html - report that even GEDMatch accounts that had been set to private could be accessed with a warrant.
1. **OPTIONAL** Office of Privacy and Civil Liberties (OPCL), Department of Justice. Overview of the Privacy Act of 1974, 2015 Edition. https://www.justice.gov/opcl/overview-privacy-act-1974-2015-edition

</details>

### Unit 4
<details>
  <summary>Categories, Categorization, and Residuality</summary>
 
<br>

1. (26p) Geoffrey C. Bowker and Susan Leigh Star. What a Difference a Name Makes - The Classification of Nursing Work. Chapter 7 of _Sorting Things Out: Classification and its Consequences_. MIT Press, 1999. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Bowker%20and%20Star.%20Sorting%20things%20Out%20ch7.pdf
1. (36p) David Kertzer and Dominique Arel. Censuses, Identity Formation, and the Struggle for Political Power. Chapter 1 of _Census and Identity: The Politics of Race, Ethnicity, and Language in National Censuses_. Cambridge University Press, 2002. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Kertzer%20and%20Arel.%20%20Census%20and%20Identity%20ch1.pdf
1. (11p) Bonnie Ruberg and Spencer Ruelos. Data for Queer Lives: How LGBTQ Gender and Sexuality Identities Challenge Norms of Demographics. _Big Data & Society_, June 2020, https://journals.sagepub.com/doi/full/10.1177/2053951720933286
1. **Case Study (for discussion)**: Gender Categories and Counting the Trans Population
   * Jan Hoffman. Estimate of U.S. Transgender Population Doubles to 1.4 Million Adults. _New York Times_, July 1, 2016. https://www.nytimes.com/2016/07/01/health/transgender-population.html 
   * Esther L. Meerwijk and Jae M. Sevelius. Transgender Population Size in the United States: a Meta-Regression of Population-Based Probability Samples. _Am J Public Health._ 2017 February; 107(2): e1–e8. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5227946/ - 2017 meta-analysis, slightly lower estimate
   * Amy J. Ko. 100 hours of name change labor. https://medium.com/bits-and-behavior/100-hours-of-name-change-labor-c652c22a89b9 (written by a colleague and friend about her process of transitioning, from an information science perspective)
   * **SKIM** Mar Hicks. Hacking the Cis-tem. _IEEE Annals of the History of Computing_. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Hicks.%20Hacking%20the%20Cis-Tem.pdf - discusses the history of gender categories in computing systems
   * **SKIM** Melina Wenner Moyer. Sexism Starts in Childhood. _Slate_, Nov. 2017. http://www.slate.com/articles/life/the_kids/2017/11/how_to_stop_sexism_and_raise_a_son_who_respects_women.html - discusses the way that children tacitly learn the importance of certain categories like gender in our social worlds
1. **OPTIONAL** Cynthia Dwork and Deirdre K Mulligan. It's not privacy, and it's not fair. _Stanford Law Review_ (Sept. 2013). https://www.stanfordlawreview.org/online/privacy-and-big-data-its-not-privacy-and-its-not-fair/
1. **OPTIONAL** Inioluwa Deborah Raji, Genevieve Fried (2021). About Face: A Survey of Facial Recognition Evaluation. AAAI 2020 Workshop on AI Evaluation. https://arxiv.org/abs/2102.00813
1. **OPTIONAL** Kate Crawford and Trevor Paglen. Excavating AI: The Politics of Training Sets for Machine Learning. September 19, 2019 (analysis accompanying the ImageNet Roulette demo). https://excavating.ai
1. **OPTIONAL** David Valentine. The Categories Themselves. _GLQ: A Journal of Lesbian and Gay Studies,_ 10.2 (Jan. 2004), 215–220. https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Valentine.%20The%20Categories%20Themselves.pdf
1. **OPTIONAL** Rebecca C. Hetey, Jennifer L. Eberhardt. The Numbers Don’t Speak for Themselves: Racial Disparities and the Persistence of Inequality in the Criminal Justice System. _Current Directions in Psychological Science_, 27:3, 2018. https://journals.sagepub.com/doi/full/10.1177/0963721418763931
</details>

### Unit 5
<details>
  <summary>Frameworks for Analyzing Privacy</summary>

<br>

1. (7p) **READ 479-483, 490-491** Solove, Daniel J. (2006). A Taxonomy of Privacy. _University of Pennsylvania Law Review,_ 154:3 (January 2006), p. 477. https://ssrn.com/abstract=667622
1. (14p) Nissenbaum, Helen F. (2011). A Contextual Approach to Privacy Online. _Daedalus_ 140:4 (Fall 2011), 32-48. https://ssrn.com/abstract=2567042
1. (16p) Mulligan, Deirdre K., Koopman, Colin and Doty, Nick (2016). Privacy is an essentially contested concept: a multi-dimensional analytic for mapping privacy. _Philosophical Transactions of The Royal Society A: Mathematical Physical and Engineering Sciences_, 374(2083):20160118 (December 2016). http://doi.org/10.1098/rsta.2016.0118
1. (25p) **READ 1099-1123** Solove, Daniel J. (2002). Conceptualizing Privacy. _California Law Review_ 90.4 (July 2002). https://doi.org/10.15779/Z382H8Q
1. **Case Study (for discussion)**: IoT and children's privacy
   * Iain Thompson. Hello Barbie: Hang on, this Wi-Fi doll records your child's voice? _The Register_, February 19, 2015. https://www.theregister.co.uk/2015/02/19/hello_barbie/
   * Marie-Helen Maras. 4 Ways “Internet of Things” Toys Endanger Children. _Scientific American_, May 10, 2018. https://www.scientificamerican.com/article/4-ways-internet-of-things-toys-endanger-children/ (more security-focused, but touches on privacy concerns as well)
1. **OPTIONAL** A. Acquisti, L. Brandimarte, and G. Loewenstein. Privacy and human behavior in the age of information. _Science_ 347.6221 (Jan. 2015), pp. 509–514. https://doi.org/10.1126/science.aaa1465.
1. **OPTIONAL** Daniel J. Solove. "'I've Got Nothing to Hide' and Other Misunderstandings of Privacy." San Diego Law Review, Vol. 44, p. 745, 2007, GWU Law School Public Law Research Paper No. 289. https://ssrn.com/abstract=998565
</details>

### Unit 6
<details>
  <summary>The Shifting Sands of Privacy Protection Regulation</summary>

<br>

1. (22p) **READ Chapter 1 (13-17), Chapter 2 (19-35).** The OECD Privacy Framework (2013 update on 1980 report). http://www.oecd.org/sti/ieconomy/oecd_privacy_framework.pdf
1. (34p) **SKIM** Data Guidance and Future of Privacy Forum. Comparing Privacy Laws: GDPR v. CCPA. https://fpf.org/wp-content/uploads/2018/11/GDPR_CCPA_Comparison-Guide.pdf
1. (11p) **READ 1-2, SKIM rest** Federal Reserve. Federal Trade Commission Act Section 5: Unfair or Deceptive Acts or Practices. _Consumer Compliance Handbook._ https://www.federalreserve.gov/boarddocs/supmanual/cch/ftca.pdf
1. (~7p) A Brief Overview of the Federal Trade Commission's Investigative, Law Enforcement, and Rulemaking Authority. https://www.ftc.gov/about-ftc/what-we-do/enforcement-authority
1. **SKIM** FTC. Children's Online Privacy Protection Rule ("COPPA") (Text of Rule). https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule
1. **OPTIONAL** FTC. Protecting Children’s Privacy Under COPPA: A Survey on Compliance. https://www.ftc.gov/sites/default/files/documents/rules/children%E2%80%99s-online-privacy-protection-rule-coppa/coppasurvey.pdf
1. **OPTIONAL** California Attorney General. Making Your Privacy Practices Public: Recommendations on Developing a Meaningful Privacy Policy. 
May 2014. https://oag.ca.gov/sites/all/files/agweb/pdfs/cybersecurity/making_your_privacy_practices_public.pdf
1. **OPTIONAL** Federal Trade Commission Act. https://www.ftc.gov/sites/default/files/documents/statutes/federal-trade-commission-act/ftc_act_incorporatingus_safe_web_act.pdf
1. **OPTIONAL** Guidelines on the Right to Data Portability. https://ec.europa.eu/information_society/newsroom/image/document/2016-51/wp242_en_40852.pdf
1. **OPTIONAL** Data Portability FAQ. https://ec.europa.eu/information_society/newsroom/image/document/2016-51/wp242_annex_en_40854.pdf
</details>

### Unit 7
<details>
  <summary>Deidentification, Reidentification, and the Limits of “Anonymous” Data</summary>

<br>

1. (9p) Arvind Narayanan and Edward W. Felten. No silver bullet: De-identification still doesn't work. https://www.cs.princeton.edu/~arvindn/publications/no-silver-bullet-de-identification.pdf
1. (12p) Cynthia Dwork. Differential Privacy. _33rd International Colloquium on Automata, Languages and Programming,_ part II (ICALP 2006). Vol. 4052. Venice, Italy: Springer Verlag, July 2006, pp. 1–12. https://www.microsoft.com/en-us/research/publication/differential-privacy/
1. NOTE - no case study this week (presentations)
1. **OPTIONAL** Latanya Sweeney. Only You, Your Doctor, and Many Others May Know. _Journal of Technology Science,_ September 2015. https://techscience.org/a/2015092903/
1. **OPTIONAL** Arvind Narayanan and Vitaly Shmatikov. How To Break Anonymity of the Netflix Prize Dataset. https://arxiv.org/abs/cs/0610105v2
1. **OPTIONAL** Chris Whong. FOILing NYC's Taxi Trip Data. https://chriswhong.com/open-data/foil_nyc_taxi/
1. **OPTIONAL** Yves-Alexandre de Montjoye, César A. Hidalgo, Michel Verleysen, and Vincent D. Blondel. Unique in the Crowd: The privacy bounds of human mobility. _Scientific Reports_ 3, 1376 (2013). https://doi.org/10.1038/srep01376
1. **OPTIONAL** Fida Kamal Dankar and Khaled El Emam. Practicing differential privacy in health care: A review. _Trans. Data Privacy_ 6.1 (2013), pp. 35–67.
1. **OPTIONAL** Luc Rocher, Julien M. Hendrickx and Yves-Alexandre de Montjoye. Estimating the success of re-identifications in incomplete datasets using generative models. _Nature Communications_ volume 10, Article number: 3069 (2019). https://www.nature.com/articles/s41467-019-10933-3
1. **OPTIONAL** Steven M. Bellovin, Preetam K. Dutta, and Nathan Reitinger. Privacy and Synthetic Datasets. _Stanford Technology Law Review_ 22:1 (2019). https://law.stanford.edu/publications/privacy-and-synthetic-datasets/
</details>

### Unit 8
<details>
  <summary>Algorithmic Bias and Opacity</summary>

<br>

1. (12p) Anna Lauren Hoffman. Where Fairness Fails: Data, algorithms, and the limits of antidiscrimination discourse. _Information, Communication, and Society,_ 22:7 (2019). https://github.com/UC-Berkeley-I-School/w231/blob/master/Readings/Hoffmann.%20Where%20Fairness%20Fails.pdf
1. (12p) Jenna Burrell. How the machine thinks: Understanding opacity in machine learning algorithms. _Big Data & Society_ 3:1 (2016). https://doi.org/10.1177/2053951715622512
1. (7p) Nicholas Diakopoulos. Accountability in Algorithmic Decision Making. _Communications of the ACM,_ February 2016, Vol. 59 No. 2, Pages 56-62. https://cacm.acm.org/magazines/2016/2/197421-accountability-in-algorithmic-decision-making/fulltext
1. (6p) Tad Hirsch et al. Designing Contestability: Interaction Design, Machine Learning, and Mental Health. _Proceedings of DIS (Designing Interactive Systems Conference),_ 2017: 95–99. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5590649/pdf/nihms892407.pdf
1. (15p) **SKIM** Joy Buolamwini and Timnit Gebru. Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. _Proceedings of Machine Learning Research_ 81:1–15 (2018). http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf
1. **Case Study (for discussion)**: algorithmic filter bubbles - **SKIM the following to get a sense of what's going on here:**
   * Staff (2017). How Filter Bubbles Distort Reality: Everything You Need to Know. _Farnam Street Blog._ https://fs.blog/2017/07/filter-bubbles/ (overview of filter bubbles)
   * Lewis, Becca (2018). Alternative Influence: Broadcasting the Reactionary Right on YouTube. _Data & Society Report_. https://datasociety.net/library/alternative-influence/ (focus on executive summary, introduction, part 3, conclusion) 
   * Bozdag, E., van den Hoven, J. (2015). Breaking the filter bubble: democracy and design. _Ethics and Information Technology_ 17, 249–265. https://link.springer.com/article/10.1007/s10676-015-9380-y
   * **SKIM** Fernandex Campbell, Alexia (2019). Facebook allowed companies to post job ads only men could see. Now that’s changing. _Vox.com_, March 21. https://www.vox.com/2019/3/21/18275746/facebook-settles-ad-discrimination-lawsuits (a lawsuit against Facebook on filter bubbles in advertising that were implicated protected groups) 
   * **SKIM** Mulligan, Deirdre K. and Daniel Griffin. Rescripting Search to Respect the Right to Truth. _Georgetown Law Review._ https://georgetownlawtechreview.org/wp-content/uploads/2018/07/2.2-Mulligan-Griffin-pp-557-84.pdf (uses human rights frameworks to argue against search results that are false in a way that erase past violations of human rights, specifically holocaust denial - not as specifically about filter bubbles but implicates the reality distortion they can amplify)
1. **OPTIONAL** Sarah Myers West. Redistribution and Rekognition: A Feminist Critique of Algorithmic Fairness. _Catalyst Journal_ 6:2 (2020). https://catalystjournal.org/index.php/catalyst/article/view/33043
1. **OPTIONAL** Solon Barocas and Andrew Selbst. Big Data's Disparate Impact. 104 _California Law Review_ 671 (2016). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899
1. **OPTIONAL** Samir Passi and Solon Barocas. 2019. Problem Formulation and Fairness. _FAT* 2019_, 39–48. https://doi.org/10.1145/3287560.3287567
1. **OPTIONAL** Mulligan, Deirdre K. and Kluttz, Daniel and Kohli, Nitin. Shaping Our Tools: Contestability as a Means to Promote Responsible Algorithmic Decision Making in the Professions (July 7, 2019). http://dx.doi.org/10.2139/ssrn.3311894
1. **OPTIONAL** Marco Almada. Human Intervention in Automated Decision-Making: Toward the Construction of Contestable Systems. _ICAIL 2019_. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3264189
1. **OPTIONAL** Mike Ananny and Kate Crawford. Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. _New Media & Society_, 2016. http://mike.ananny.org/papers/anannyCrawford_seeingWithoutKnowing_2016.pdf
1. **OPTIONAL** Ali Alkhatib and Michael Bernstein. Street–Level Algorithms: A Theory at the Gaps Between Policy and Decisions.
https://hci.stanford.edu/publications/2019/streetlevelalgorithms/streetlevelalgorithms-chi2019.pdf
1. **OPTIONAL** Tarleton Gillespie. The Relevance of Algorithms. _Media Technologies_ (2014), pp. 167–194. https://doi.org/10.7551/mitpress/9780262525374.003.0009
1. **OPTIONAL** _Coded Bias_ (documentary film). https://www.codedbias.com
</details>

### Unit 9
<details>
  <summary>Due Process and Consumer Protections with Big Data</summary>

<br>

1. (25p) **(READ: Executive Summary, Potentially Applicable Laws, Questions for Legal Compliance)** FTC. Big Data: A Tool for Inclusion or Exclusion? Understanding the Issues https://www.ftc.gov/system/files/documents/reports/big-data-tool-inclusion-or-exclusion-understanding-issues/160106big-data-rpt.pdf
1. (23p) **(READ: Sections IV and V)** Andrew Guthrie Ferguson. Big Data and Predictive Reasonable Suspicion. 163 _University of Pennsylvania Law Review_ 327 (2015). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2394683
1. (66p) **(SKIM)** Danielle Keats Citron. Technological Due Process. _Washington University Law Review_ 85 (2007). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1012360
1. (37p) **(SKIM)** Kate Crawford and Jason Schultz. Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms. _Boston College Law Review_ 55.93 (2014). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2325784
1. **(SKIM)** CalECPA (state bill 178). Leno. Privacy: electronic communications: search warrant. https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=201520160SB178
1. **Case Study (for discussion)**: Discrimination in Hiring Algorithms - **SKIM the following to get a sense of what's going on here:**
   * Rachel Goodman. Why Amazon’s Automated Hiring Tool Discriminated Against Women. ACLU, October 12, 2018. https://www.aclu.org/blog/womens-rights/womens-rights-workplace/why-amazons-automated-hiring-tool-discriminated-against
   * Drew Harwell. Rights group files federal complaint against AI-hiring firm HireVue, citing ‘unfair and deceptive’ practices. _The Washington Post_, November 6, 2019. https://www.washingtonpost.com/technology/2019/11/06/prominent-rights-group-files-federal-complaint-against-ai-hiring-firm-hirevue-citing-unfair-deceptive-practices/
   * Karen Hao. Facebook’s ad-serving algorithm discriminates by gender and race. _MIT Technology Review_, April 5, 2019.  https://www.technologyreview.com/2019/04/05/1175/facebook-algorithm-discriminates-ai-bias/
   * Kate Cox. New Google rule bans discriminatory targeting for housing ads. _Ars Technica_, June 2020. https://arstechnica.com/tech-policy/2020/06/new-google-rule-bans-discriminatory-targeting-for-housing-ads/

</details>

### Unit 10
<details>
  <summary>Impact Assessments and Other Institutional Approaches to Data Science Ethics</summary>

<br>

1. (4p) **(READ 6-10, SKIM REST)** Inioluwa Deborah Raji et al. Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing. _FAccT 2020._ https://arxiv.org/pdf/2001.00973.pdf
1. (4p) **(READ 3-6, SKIM REST)** Margaret Mitchell et al. Model Cards for Model Reporting. _FAT* 2019_. https://arxiv.org/pdf/1810.03993.pdf
1. (21p) Charles Raab and David Wright. Surveillance: Extending the Limits of Privacy Impact Assessment. https://doi.org/10.1007/978-94-007-2543-0_17
1. (3p) **(READ 1-3)** Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products. _AIES 2019._ https://www.aies-conference.com/2019/wp-content/uploads/2019/01/AIES-19_paper_223.pdf
1. **Case Study (for discussion)**: TSA Privacy Impact Assessments - **SKIM the following to get a sense of PIAs in action:**
   * TSA and Robin Kane. Privacy Impact Assessment Update for TSA Whole Body Imaging. Department of Homeland Security, 2009. https://www.dhs.gov/sites/default/files/publications/privacy-tsa-pia-32-a-ait.pdf
   * TSA and Robin Kane. PIA for TSA Advanced Imaging Technology. Department of Homeland Security, 2011. https://fdocuments.us/document/tsa-advanced-imaging-technology-homeland-security-nbsppdf-filefor.html 
   * Joe Sharkey. A Farewell to 'Nudity' at Airport Checkpoints. _The New York Times_ (Jan. 2013). http://www.nytimes.com/2013/01/22/business/a-farewell-to-nudity-at-airport-checkpoints.html
   * Katie Rogers. T.S.A. Defends Treatment of Transgender Air Traveler. _The New York Times_ (Sept. 2015). https://www.nytimes.com/2015/09/23/us/shadi-petosky-tsa-transgender.html
   * Lucas Waldron and Brenda Medina. When Transgender Travelers Walk Into Scanners, Invasive Searches Sometimes Wait on the Other Side. _Propublica_, August 26, 2019.  https://www.propublica.org/article/tsa-transgender-travelers-scanners-invasive-searches-often-wait-on-the-other-side
1. **OPTIONAL** NIST. Privacy Framework Factsheet. 2018. https://www.nist.gov/system/files/documents/2018/09/04/privacyframeworkfactsheet-sept2018.pdf

</details>

### Unit 11
<details>
  <summary>Additional Legal Limitations of Data</summary>

<br>

1. Copyright Act 102, 106(a), 107. https://www.copyright.gov/title17/92chap1.html#102
1. Computer Fraud and Abuse Act, 18 USC. https://www.law.cornell.edu/uscode/text/18/1030.
1. **Case Study (for discussion)**: ownership of DTC genetic data
   * [UPDATED] https://www.ftc.gov/system/files/documents/public_comments/2015/10/00057-98101.pdf
   * [UPDATED] Optional - for overview: https://sitn.hms.harvard.edu/flash/2018/understanding-ownership-privacy-genetic-data/
   * https://www.snopes.com/fact-check/ancestry-dna-steal-own/ 
1. **OPTIONAL** Feist Pubs., Inc. v. Rural Tel. Svc. Co., Inc. 499 U.S. 340 (1991). 1991. https://scholar.google.com/scholar_case?case=1195336269698056315
1. **OPTIONAL** ProCD, INC. v. ZEIDENBERG, 86 F.3d 1447 (7th. Cir. 1996). 1996. https://scholar.google.com/scholar_case?case=11811009805458694240
</details>

### Unit 12
<details>
  <summary>Technical Approaches to Algorithmic Fairness, Accountability, and Transparency</summary>

<br>

1. (17p) Selbst, Andrew D., danah boyd, Sorelle Friedler, Suresh Venkatasubramanian, and Janet Vertesi. Fairness and Abstraction in Sociotechnical Systems. _FAT* 2019_, 59-68. https://dl.acm.org/doi/10.1145/3287560.3287598
1. (5p) Hila Gonen, Yoav Goldberg. Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them. https://arxiv.org/abs/1903.03862
1. **SKIM/EXPLORE** Shan Carter, Zan Armstrong, Ludwig Schubert, Ian Johnson, Chris Olah. Exploring Neural Networks with Activation Atlases. https://distill.pub/2019/activation-atlas/
1. NOTE - no case study this week (presentations)
1. **OPTIONAL** Bender, Emily M., Angelina McMillan-Major, Timnit Gebru, Margaret Mitchell (2021). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? FAccT 2021. http://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf
1. **OPTIONAL** Tolga Bolukbasi et al. Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings. https://arxiv.org/abs/1607.06520
1. **OPTIONAL** Thomas Manzini, Yao Chong Lim, Yulia Tsvetkov, Alan W Black. Black is to Criminal as Caucasian is to Police: Detecting and Removing Multiclass Bias inWord Embeddings. https://arxiv.org/abs/1904.04047
1. **OPTIONAL** Harini Suresh and John Guttag. A Framework for Understanding Unintended Consequences of Machine Learning. https://arxiv.org/abs/1901.10002 (discussed here: https://www.youtube.com/watch?v=IRWaE1u9mDM)
1. **OPTIONAL** Deven Shah, H. Andrew Schwartz, and Dirk Hovy. Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview. https://arxiv.org/abs/1912.11078 (presentation here: https://www.youtube.com/watch?v=EMnNe5HJF5o)
1. **OPTIONAL** Leilani H. Gilpin, David Bau, Ben Z. Yuan, Ayesha Bajwa, Michael Specter, Lalana Kagal. Explaining Explanations: An Overview of Interpretability of Machine Learning. https://arxiv.org/abs/1806.00069
  
</details>

### Unit 13
<details>
  <summary>Power and Countervailance</summary>

<br>

1. (15p) Gary T. Marx. A Tack in the Shoe: Neutralizing and Resisting the New Surveillance. _Journal of Social Issues_ 59:2, 2003. https://web.mit.edu/gtmarx/www/tack.html
1. (3+p) **(READ Executive Summary, SKIM rest)** Emanuel Moss and Jacob Metcalf. Ethics Owners: A New Model of Organizational Responsibility in Data-Driven Technology Companies. https://datasociety.net/wp-content/uploads/2020/09/Ethics-Owners_20200923-DataSociety.pdf
1. (28p) Deirdre K. Mulligan and Daniel S. Griffin. Rescripting Search to Respect the Right to Truth. 2 _Georgetown Law Technology Review_ 557 (2018). https://georgetownlawtechreview.org/rescripting-search-to-respect-the-right-to-truth/GLTR-07-2018/
1. **Case Study (for discussion)**: in class, we'll be doing a speculative writing exercise imagining future technologies and regulatory environments for them. To prepare, please watch/read one piece of speculative science fiction involving technology and implicating some of the ideas we've discussed in class. Potential sources include _Black Mirror_ episodes; near-future sci-fi books or movies like _Minority Report,_ _Gattaca,_ _A Scanner Darkly,_ _Ex Machina,_ etc. that involve technology ethics; or any of the three short films at https://www.screeningsurveillance.com.
1. **OPTIONAL** Rita Raley. Dataveillance and Countervailance. Chapter 7, _Raw Data is an Oxymoron_. http://raley.english.ucsb.edu/wp-content/DV-uncorrected-proofs.pdf
1. **OPTIONAL** Finn Brunton and Helen Nissenbaum. Vernacular Resistance to data collection and analysis. _First Monday_ 16:5 (2011). https://firstmonday.org/ojs/index.php/fm/article/view/3493
1. **OPTIONAL** ACM Code of Ethics. https://www.acm.org/code-of-ethics
1. **OPTIONAL** Chelsea Barabas, Colin Doyle, JB Rubinovitz, and Karthik Dinakar. Studying Up: Reorienting the study of algorithmic fairness around issues of power. _FAccT 2020._ https://dl.acm.org/doi/abs/10.1145/3351095.3372859
1. **OPTIONAL** Green B, Viljoen S. Algorithmic Realism: Expanding the Boundaries of Algorithmic Thought. _FAccT 2020._  https://scholar.harvard.edu/bgreen/publications/algorithmic-realism-expanding-boundaries-algorithmic-thought
1. **OPTIONAL**  Ali Alkhatib. Anthropological/Artificial Intelligence & the HAI. https://ali-alkhatib.com/blog/anthropological-intelligence
1. **OPTIONAL**  Ben Green. Data Science as Political Action: Grounding Data Science in a Politics of Justice. https://scholar.harvard.edu/bgreen/publications/data-science-political-action-grounding-data-science-politics-justice

</details>


